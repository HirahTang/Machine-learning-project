{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOHwLqgYiikn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37077f98-94ab-420f-eca3-804da08fb2d7"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e88qAdo3iwfF",
        "outputId": "c66f0831-ed24-4c18-e1d6-a0249d3062b8"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week5()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-08 08:23:24--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-12-08 08:23:25 (39.8 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "qzrQI380i16w",
        "outputId": "37e87156-8448-4d08-ca24-95d55b07c9be"
      },
      "source": [
        "!pip install 'h5py==2.10.0' --force-reinstall\n",
        "!pip3 install keras==2.0.6\n",
        "!pip3 install tensorflow==1.2.1\n",
        "!pip install numpy==1.19.5"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.7\n",
            "  Downloading numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 23.0 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lucid 0.3.10 requires umap-learn, which is not installed.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.4.0 which is incompatible.\n",
            "lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.21.4 which is incompatible.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.4 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.4 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py",
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.0.6\n",
            "  Using cached Keras-2.0.6-py3-none-any.whl\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.7/dist-packages (from keras==2.0.6) (1.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras==2.0.6) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.0.6) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from theano->keras==2.0.6) (1.21.4)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from theano->keras==2.0.6) (1.4.1)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.7.0\n",
            "    Uninstalling keras-2.7.0:\n",
            "      Successfully uninstalled keras-2.7.0\n",
            "Successfully installed keras-2.0.6\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==1.2.1 (from versions: 1.13.1, 1.13.2, 1.14.0, 1.15.0, 1.15.2, 1.15.3, 1.15.4, 1.15.5, 2.0.0, 2.0.1, 2.0.2, 2.0.3, 2.0.4, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.2.0rc0, 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3, 2.4.0rc4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0rc0, 2.5.0rc1, 2.5.0rc2, 2.5.0rc3, 2.5.0, 2.5.1, 2.5.2, 2.6.0rc0, 2.6.0rc1, 2.6.0rc2, 2.6.0, 2.6.1, 2.6.2, 2.7.0rc0, 2.7.0rc1, 2.7.0)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tensorflow==1.2.1\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogvy4lTGiiko"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "TvOtBqrsiikp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058a106e-1191-483f-dd48-d063621c797d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozMQRedpiikq"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "ls9BnZZAiikq"
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "MYcapZvdiikr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32354de8-e8cb-4d1f-a6dd-97c111f0ffd2"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "yBF8IfXkiikr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "534ca14a-8ff6-4d7f-fd65-de0a27d62800"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length: 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5HHUdR5iiks"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "9UocJd_fiiks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159b5286-2492-4925-e700-76ce4d331fa7"
      },
      "source": [
        "tokens = set(''.join(names))\n",
        " ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = sorted(list(tokens))\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_tokens: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Nqdu3uMiikt"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "6SxyW8_Eiikt"
      },
      "source": [
        "token_to_id = {}\n",
        "for i in range(len(tokens)):\n",
        "  token_to_id[tokens[i]] = i\n",
        "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "5WHbfkT6iiku"
      },
      "source": [
        "def to_matrix(names, max_len=None, pad= 0 , dtype=np.int32):\n",
        "#    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "#    print(names_ix)\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "aB5y5pOniiku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd6f81f1-e31b-43c9-ad7b-ace68cd79739"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 0  3 30 29 35 29 33 40  0]\n",
            " [ 0  9 40 43 46 53  0  0  0]\n",
            " [ 0 18 46 37 47 47 37 33  0]\n",
            " [ 0  9 37 43 50 29 42 42 33]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzrvWhYHiiku"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "IhHeYWlxiikv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17a98ba9-3dcd-4c9a-d981-adf336534bef"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "YQxCNDBEiikw"
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation = 'tanh') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation = 'softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amcXwycyiikw"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "zoW7T7pKiikw"
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t], 1) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyCsQpJxiikx"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "G7-QqK3kMSKI",
        "outputId": "086f5f4f-bfd8-4852-e423-f5c519ad9341"
      },
      "source": [
        "# import numpy as \n",
        "keras.__version__"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.6'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "tXIo6shIiikx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5510e0-d9b3-4aa6-c48e-af1b439e5806"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWHetAysiiky"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "LuibHm5kiiky"
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_r8kxJ5Tiiky"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w22lmkX0arhA",
        "outputId": "fc8c401e-3c19-4dee-d846-e50741a6039d"
      },
      "source": [
        "predictions_matrix, answers_matrix"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor 'Reshape_16:0' shape=(?, 55) dtype=float32>,\n",
              " <tf.Tensor 'one_hot:0' shape=(?, 55) dtype=float32>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "LsgN78tqiikz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee65156-bcd9-4644-8ffc-2c40002a613e"
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(keras.metrics.categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN8zeh_wiikz"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "PC6RAzEYiikz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ad0c24d9-cf5e-43c1-ef77-27b28a3efa54"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYe30CZ3iikz"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "a55ko-bciik0"
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "__KIMyeTiik0"
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "fizwbavAiik0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3671a4a-c59c-40f0-bd96-c2691a978b1f"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bimelil        \n",
            " Mavau          \n",
            " Arils          \n",
            " Perlyln        \n",
            " mino           \n",
            " Yarta le       \n",
            " Silas          \n",
            " Sele  n        \n",
            " Mayne          \n",
            " Dansot         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "w7DMmKVPiik1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6c1a8b-a0ee-43ea-ae52-313b0325c2b4"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Trumpe         \n",
            " Trumpa         \n",
            " Trumppte       \n",
            " Trumpene       \n",
            " Trumpodu       \n",
            " Trumpolke      \n",
            " Trumpat        \n",
            " Trumpi         \n",
            " Trumph         \n",
            " Trumponane     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhP1pZPIiik1"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "kFAV1a-Wiik1"
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"V9vS4wJoOh1msOI2\"\n",
        "COURSERA_EMAIL = \"tanghan1995@gmail.com\""
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "gHe8dC-siik1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9371d1d7-c5dd-4d89-8ead-1c914a0d61a0"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19SCcbKIiik2"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "EaHKGrdXiik2"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "Rc3xhsquiik2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e54da7-d54a-4ffa-b725-db58dee10b18"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7f7304540d50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "WARNING: Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7f7304540d50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 55)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe8HnLqEiik2"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "bh5N6m0liik3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8730c04f-2565-4efe-fda3-d8f8089b621f"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "fRHzh84niik3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98680cf6-240f-4bfd-8a10-672cf1832616"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-27-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ]
        }
      ]
    }
  ]
}